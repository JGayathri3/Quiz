{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7d27c1-3904-4d39-a512-67b79119d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.37-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (2.31.0)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lxml>=4.9.1 (from yfinance)\n",
      "  Downloading lxml-5.2.1-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting appdirs>=1.4.4 (from yfinance)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.1.tar.gz (315 kB)\n",
      "     ---------------------------------------- 0.0/315.2 kB ? eta -:--:--\n",
      "     --- ----------------------------------- 30.7/315.2 kB 1.4 MB/s eta 0:00:01\n",
      "     ----------- --------------------------- 92.2/315.2 kB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 245.8/315.2 kB 2.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 315.2/315.2 kB 2.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.1.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 9.2 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 0.8/3.0 MB 10.6 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.5/3.0 MB 10.5 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 2.2/3.0 MB 11.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.9/3.0 MB 12.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 11.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Collecting html5lib>=1.1 (from yfinance)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->yfinance) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rushi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->yfinance) (2024.2.2)\n",
      "Downloading yfinance-0.2.37-py2.py3-none-any.whl (72 kB)\n",
      "   ---------------------------------------- 0.0/73.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.0/73.0 kB ? eta 0:00:00\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "   ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 112.2/112.2 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading lxml-5.2.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.8/3.8 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.3/3.8 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.1/3.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.9/3.8 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.6/3.8 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Building wheels for collected packages: frozendict, peewee\n",
      "  Building wheel for frozendict (pyproject.toml): started\n",
      "  Building wheel for frozendict (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for frozendict: filename=frozendict-2.4.1-cp311-cp311-win_amd64.whl size=15539 sha256=86b253b3396e8cda0146de8ea4b3591290dd30ad6d000e8841929ebd3079dc6a\n",
      "  Stored in directory: c:\\users\\rushi\\appdata\\local\\pip\\cache\\wheels\\02\\6e\\a0\\b90b693ddaaf2bde1efb47df2576175a1983aef24936f71694\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.17.1-py3-none-any.whl size=136948 sha256=3f7ef09460135d29691af04b4251a4c5af62183124aa7c5a072fdcf65ffe1c13\n",
      "  Stored in directory: c:\\users\\rushi\\appdata\\local\\pip\\cache\\wheels\\33\\d2\\ca\\79b9807826bc7ef0b86a1ee28c372daaf073f9aa8756eedd7f\n",
      "Successfully built frozendict peewee\n",
      "Installing collected packages: peewee, multitasking, appdirs, lxml, html5lib, frozendict, yfinance\n",
      "Successfully installed appdirs-1.4.4 frozendict-2.4.1 html5lib-1.1 lxml-5.2.1 multitasking-0.0.11 peewee-3.17.1 yfinance-0.2.37\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a641953f-9f68-4423-8a12-45d822310ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close  Adj Close     Volume\n",
      "Date                                                                    \n",
      "2010-01-04  7.622500  7.660714  7.585000  7.643214   6.470741  493729600\n",
      "2010-01-05  7.664286  7.699643  7.616071  7.656429   6.481930  601904800\n",
      "2010-01-06  7.656429  7.686786  7.526786  7.534643   6.378823  552160000\n",
      "2010-01-07  7.562500  7.571429  7.466071  7.520714   6.367033  477131200\n",
      "2010-01-08  7.510714  7.571429  7.466429  7.570714   6.409362  447610800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Load a time series dataset (e.g., stock prices, weather data).\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the start and end dates for the data\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2020-12-31'\n",
    "\n",
    "# Define the stock symbol (e.g., Apple Inc. - AAPL)\n",
    "stock_symbol = 'AAPL'\n",
    "\n",
    "# Load historical stock prices data from Yahoo Finance\n",
    "data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4bb59-867d-4c15-b780-676660d82a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "42/42 [==============================] - 17s 159ms/step - loss: 0.0087\n",
      "Epoch 2/80\n",
      "42/42 [==============================] - 7s 173ms/step - loss: 3.2496e-04\n",
      "Epoch 3/80\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 2.8163e-04\n",
      "Epoch 4/80\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 2.7679e-04\n",
      "Epoch 5/80\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 2.7090e-04\n",
      "Epoch 6/80\n",
      "42/42 [==============================] - 6s 152ms/step - loss: 2.5431e-04\n",
      "Epoch 7/80\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 2.7683e-04\n",
      "Epoch 8/80\n",
      "42/42 [==============================] - 6s 141ms/step - loss: 2.8395e-04\n",
      "Epoch 9/80\n",
      "42/42 [==============================] - 6s 143ms/step - loss: 2.8171e-04\n",
      "Epoch 10/80\n",
      "42/42 [==============================] - 6s 143ms/step - loss: 2.6065e-04\n",
      "Epoch 11/80\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 2.2967e-04\n",
      "Epoch 12/80\n",
      "24/42 [================>.............] - ETA: 2s - loss: 2.4109e-04"
     ]
    }
   ],
   "source": [
    "#Build a recurrent neural network (RNN) or LSTM model using Keras.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Assuming 'data' contains the loaded time series dataset (e.g., historical stock prices)\n",
    "# Let's consider 'data' has a column named 'Close' for the closing prices\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Define function to create dataset\n",
    "def create_dataset(data, time_step):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        X.append(data[i:(i+time_step), 0])\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Reshape the data into X=t, t+1, t+2, t+3 and Y=t+4\n",
    "time_step = 100  # You can adjust the time step as needed\n",
    "X_train, y_train = create_dataset(scaled_data, time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=64)\n",
    "\n",
    "# Once the model is trained, you can use it for forecasting future values\n",
    "# You can also evaluate the model's performance using appropriate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c09a05-055a-4108-af74-64ebdc52c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model to forecast future values based on historical dataimport numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Assuming 'data' contains the loaded time series dataset (e.g., historical stock prices)\n",
    "# Let's consider 'data' has a column named 'Close' for the closing prices\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Define function to create dataset\n",
    "def create_dataset(data, time_step):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        X.append(data[i:(i+time_step), 0])\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Reshape the data into input-output pairs\n",
    "time_step = 100  # You can adjust the time step as needed\n",
    "X, y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=70, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Once the model is trained, you can use it for forecasting future values\n",
    "# You can also evaluate the model's performance using appropriate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1053dcc-a41b-460e-aaec-45ace0925fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predicted and actual values\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed73d9-8eea-4160-90c7-2d4fd917f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a46192-1cee-442c-af7a-4561cf29518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    # Convolutional layer with 32 filters of size 3x3, relu activation function\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max pooling layer with pool size 2x2\n",
    "    MaxPooling2D((2, 2)),\n",
    "    # Flatten layer to flatten the input for the fully connected layers\n",
    "    Flatten(),\n",
    "    # Dense (fully connected) layer with 128 units and relu activation function\n",
    "    Dense(128, activation='relu'),\n",
    "    # Output layer with 10 units (one for each class) and softmax activation function\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a8dad-9b52-4931-9ac6-a1b9e8287f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47fbc2-65b6-4adc-a0fc-fce6de8c6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Report accuracy\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b110a7-01f6-4b11-9075-cd37869bfb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a function to create the CNN model\n",
    "def create_model(optimizer='adam', learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    # Compile the model with specified optimizer and learning rate\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=5, batch_size=64, verbose=0)\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'batch_size': [32, 64, 128]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77107211-a50c-441c-ab16-4908bc12bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define the ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "# Train the model with the ReduceLROnPlateau callback\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), callbacks=[reduce_lr])\n",
    "\n",
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
